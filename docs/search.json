[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I’m currently a junior at St. Olaf College, working towards a bachelors’ in Bioinformatics (individual major track). My academic pursuits reflect my interests in rare disease research, forensic science, and conservation ecology. I enjoy leveraging the power of data science in order to solve complex problems across disciplines."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Elise Hachfeld",
    "section": "",
    "text": "Hello! My name is Elise Hachfeld and I am a junior at St. Olaf College. I am majoring in Bioinformatics with concentrations in statistics & data science, neuroscience, and nordic studies."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Elise Hachfeld",
    "section": "Education",
    "text": "Education\nSt. Olaf College | Northfield, MN BA | Sep 2022 - May 2026"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Elise Hachfeld",
    "section": "Experience",
    "text": "Experience"
  },
  {
    "objectID": "index.html#relevant-coursework",
    "href": "index.html#relevant-coursework",
    "title": "Elise Hachfeld",
    "section": "Relevant Coursework",
    "text": "Relevant Coursework"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "projects",
    "section": "",
    "text": "EREN Research Project Analysis\n\n\nStatistical Analysis and Visualization for EREN Plot Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGutenberg Data\n\n\nAcquiring Text Data from Gutenberg.org with Theresa Worden\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRedlining in Minneapolis and St. Paul\n\n\nInvestigating Historical Redlining in Minneasota with Mary Hendrickson and Karra Howles\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnited States Nursing Home Data\n\n\nAn Exploratory Data Analysis of US Nursing Home Data from the Skilled Nursing Facility Cost Report\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/US_nursing_homes/US_nursing_homes.html",
    "href": "projects/US_nursing_homes/US_nursing_homes.html",
    "title": "Mini_Project_1",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = FALSE, message =FALSE, warnings = FALSE)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(viridis)\n\nLoading required package: viridisLite\n\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(leaflet)\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:viridis':\n\n    unemp\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(htmltools)\nlibrary(envalysis)\n\n# Import Nursing Home Data \n# https://data.cms.gov/provider-compliance/cost-report/skilled-nursing-facility-cost-report\nnursing_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/nursing_data.csv\") |&gt;\n  clean_names() |&gt;\n  select(-nursing_and_allied_health_education_activities)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 15057 Columns: 122\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): Provider CCN, Facility Name, Street Address, City, State Code, Zi...\ndbl (110): rpt_rec_num, Medicare CBSA Number, Type of Control, Total Days Ti...\nlgl   (2): Total RUG Days, Nursing and Allied Health Education Activities\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Import List of State Names and State Abbreviations for Joining nursing_data with states_sf\nstate_abbr_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/state_abbr.csv\") |&gt;\n  clean_names() |&gt;\n  select(-standard) |&gt;\n  mutate(state = str_to_lower(state))\n\nRows: 55 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): State, Standard, Postal\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Import US States Data Using sf and maps Packages\nstates_sf &lt;- read_sf(\"https://rstudio.github.io/leaflet/json/us-states.geojson\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = str_to_lower(name))\n\nstates_polygon &lt;- map_data(\"state\") |&gt;\n  select(region, group, order, lat, long)\n\n# Import State Population Data \n# https://www.pewtrusts.org/en/research-and-analysis/articles/2022/04/25/a-third-of-states-lost-population-in-2021\npop_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/2020_pop.csv\") |&gt;\n  clean_names() |&gt;\n  mutate(state = str_to_lower(state))\n\nRows: 51 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): State\ndbl (1): Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "projects/US_nursing_homes/US_nursing_homes.html#data-import",
    "href": "projects/US_nursing_homes/US_nursing_homes.html#data-import",
    "title": "Mini_Project_1",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = FALSE, message =FALSE, warnings = FALSE)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(viridis)\n\nLoading required package: viridisLite\n\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(leaflet)\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:viridis':\n\n    unemp\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(htmltools)\nlibrary(envalysis)\n\n# Import Nursing Home Data \n# https://data.cms.gov/provider-compliance/cost-report/skilled-nursing-facility-cost-report\nnursing_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/nursing_data.csv\") |&gt;\n  clean_names() |&gt;\n  select(-nursing_and_allied_health_education_activities)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 15057 Columns: 122\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): Provider CCN, Facility Name, Street Address, City, State Code, Zi...\ndbl (110): rpt_rec_num, Medicare CBSA Number, Type of Control, Total Days Ti...\nlgl   (2): Total RUG Days, Nursing and Allied Health Education Activities\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Import List of State Names and State Abbreviations for Joining nursing_data with states_sf\nstate_abbr_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/state_abbr.csv\") |&gt;\n  clean_names() |&gt;\n  select(-standard) |&gt;\n  mutate(state = str_to_lower(state))\n\nRows: 55 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): State, Standard, Postal\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Import US States Data Using sf and maps Packages\nstates_sf &lt;- read_sf(\"https://rstudio.github.io/leaflet/json/us-states.geojson\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = str_to_lower(name))\n\nstates_polygon &lt;- map_data(\"state\") |&gt;\n  select(region, group, order, lat, long)\n\n# Import State Population Data \n# https://www.pewtrusts.org/en/research-and-analysis/articles/2022/04/25/a-third-of-states-lost-population-in-2021\npop_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/2020_pop.csv\") |&gt;\n  clean_names() |&gt;\n  mutate(state = str_to_lower(state))\n\nRows: 51 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): State\ndbl (1): Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "projects/US_nursing_homes/US_nursing_homes.html#plot-1-numeric-variable",
    "href": "projects/US_nursing_homes/US_nursing_homes.html#plot-1-numeric-variable",
    "title": "Mini_Project_1",
    "section": "Plot 1 (Numeric variable)",
    "text": "Plot 1 (Numeric variable)\n\n\n\n\n\n\n\n\n\n      min       Q1   median       Q3      max     mean       sd     n missing\n 21.07186 43.97446 51.82551 62.96279 101.0228 53.93941 16.72434 15527       0\n\n\nAlt-Text: This choropleth plot displays the 48 contiguous US states colored by the number of nursing home beds available per 10,000 people. The data ranges from about 21 to 101 beds per 10,000 people. The western half of the US has a relatively low number of beds, while the Midwest has more. Iowa has the greatest number of beds. The data were obtained from the Skilled Nursing Facility Cost Report and 2020 Decennial Population Data.\nSANILAC COUNTY MEDICAL CARE FACILITY of MI had 22,287 beds and was removed from the data for this analysis."
  },
  {
    "objectID": "projects/US_nursing_homes/US_nursing_homes.html#plot-2-categorical-variable",
    "href": "projects/US_nursing_homes/US_nursing_homes.html#plot-2-categorical-variable",
    "title": "Mini_Project_1",
    "section": "Plot 2 (categorical variable)",
    "text": "Plot 2 (categorical variable)\nNote: I created both my categorical variables from numerical variables in the data set because there weren’t any appropriate existing variables.\n\n\n\n\n\n\n\n\n\nAlt-Text: This choropleth plot displays the 48 contiguous US states colored by the most common type of ownership for nursing homes in the state. The three types of ownership are Nonprofit, Proprietary and Governmental. All of the states are dominated by Proprietary nursing homes except for four: North Dakota, South Dakota and Minnesota have more Nonprofit nursing homes than other types and Indiana has more Governmental nursing homes. The data were obtained from the Skilled Nursing Facility Cost Report."
  },
  {
    "objectID": "projects/US_nursing_homes/US_nursing_homes.html#plot-1-numeric",
    "href": "projects/US_nursing_homes/US_nursing_homes.html#plot-1-numeric",
    "title": "Mini_Project_1",
    "section": "Plot 1 (numeric)",
    "text": "Plot 1 (numeric)"
  },
  {
    "objectID": "projects/US_nursing_homes/US_nursing_homes.html#plot-2-categorical",
    "href": "projects/US_nursing_homes/US_nursing_homes.html#plot-2-categorical",
    "title": "Mini_Project_1",
    "section": "Plot 2 (categorical)",
    "text": "Plot 2 (categorical)\nNote: there are no observations in the $20 million - $25 million category so I did not provide a color for that level.\n\n\n[1] \"Less than $10 million\"     \"$10 million - $15 million\"\n[3] \"$15 million - $20 million\" \"Greater than $25 million\" \n\n\n\n\n\n\nTWIN FOUNTAINS HOME of GA had a gross revenue of $1,300,406,865 and was removed for this analysis."
  },
  {
    "objectID": "projects/US_nursing_homes/index.html#plot-1-numeric-variable",
    "href": "projects/US_nursing_homes/index.html#plot-1-numeric-variable",
    "title": "United States Nursing Home Data",
    "section": "Plot 1 (Numeric variable)",
    "text": "Plot 1 (Numeric variable)\n\nnursing_summary |&gt;\n  ggplot(aes(long, lat, group = group)) + \n  geom_polygon(aes(fill = beds_10k), color = \"black\") + \n  labs(title = \"Nursing Home Beds Available Nationwide\",\n       fill = \"Beds Per\\n10,000 People\",\n       caption = \"Skilled Nursing Facility Cost Report (Data.CMS.gov)\\n2020 Decennial Population Data (pewtrusts.org) \") +\n  coord_map() +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        plot.caption = element_text(hjust = 0),\n                plot.title = element_text(face = \"bold\"),\n                legend.title = element_text(face = \"bold\")) +\n  scale_fill_viridis()  \n\n\n\n\n\n\n\nfavstats(~beds_10k, data = nursing_summary)\n\n      min       Q1   median       Q3      max     mean       sd     n missing\n 21.07186 43.97446 51.82551 62.96279 101.0228 53.93941 16.72434 15527       0\n\n\nAlt-Text: This choropleth plot displays the 48 contiguous US states colored by the number of nursing home beds available per 10,000 people. The data ranges from about 21 to 101 beds per 10,000 people. The western half of the US has a relatively low number of beds, while the Midwest has more. Iowa has the greatest number of beds. The data were obtained from the Skilled Nursing Facility Cost Report and 2020 Decennial Population Data.\nSANILAC COUNTY MEDICAL CARE FACILITY of MI had 22,287 beds and was removed from the data for this analysis."
  },
  {
    "objectID": "projects/US_nursing_homes/index.html#plot-2-categorical-variable",
    "href": "projects/US_nursing_homes/index.html#plot-2-categorical-variable",
    "title": "United States Nursing Home Data",
    "section": "Plot 2 (categorical variable)",
    "text": "Plot 2 (categorical variable)\nNote: I created both my categorical variables from numerical variables in the data set because there weren’t any appropriate existing variables.\n\nnursing_summary |&gt;\n  ggplot(mapping = aes(x = long, y = lat, group = group)) + \n    geom_polygon(aes(fill = top_control_type), color = \"black\") + \n    coord_map() + \n    theme_void() +  \n  theme(legend.position = \"bottom\",\n        plot.caption = element_text(hjust = 0),\n                plot.title = element_text(face = \"bold\"),\n                legend.title = element_text(face = \"bold\")) +\n  labs(title = \"Most Common Type of Nursing Home Ownership\",\n       fill = \"Type of Control\",\n       caption = \"Data: Skilled Nursing Facility Cost Report (Data.CMS.gov)\") +\n    scale_fill_manual(values = c(\"#77AB43\", \"#008FD5\", \"#FF2700\"))\n\n\n\n\n\n\n\n\nAlt-Text: This choropleth plot displays the 48 contiguous US states colored by the most common type of ownership for nursing homes in the state. The three types of ownership are Nonprofit, Proprietary and Governmental. All of the states are dominated by Proprietary nursing homes except for four: North Dakota, South Dakota and Minnesota have more Nonprofit nursing homes than other types and Indiana has more Governmental nursing homes. The data were obtained from the Skilled Nursing Facility Cost Report."
  },
  {
    "objectID": "projects/US_nursing_homes/index.html#plot-1-numeric",
    "href": "projects/US_nursing_homes/index.html#plot-1-numeric",
    "title": "United States Nursing Home Data",
    "section": "Plot 1 (numeric)",
    "text": "Plot 1 (numeric)\n\nnursing_summary &lt;- nursing_summary |&gt;\n  mutate(num_labs_1 = str_c(name, \": \", snf_mean_stay_round, \" days\"))\npal &lt;- colorNumeric(\"Blues\", nursing_summary$snf_mean_stay_round)\n\n\nleaflet(nursing_summary) |&gt;\n  addTiles() |&gt; \n  setView(lng = -96.25,\n          lat = 40,\n          zoom = 3.5) |&gt;\n  addPolygons(weight = 2,\n              opacity = 1,\n              color = \"black\",\n              fillColor = ~ pal(nursing_summary$snf_mean_stay_round),\n              fillOpacity = 0.7,\n              label = ~ num_labs_1,\n              highlightOptions = highlightOptions(weight = 4,\n                                                  color = \"#668\",\n                                                  fillOpacity = 0.8,\n                                                  bringToFront = TRUE),\n              labelOptions = labelOptions(style = list(\"font-weight\" = \"normal\",\n                                                       padding = \"3px 8px\"),\n                                          textsize = \"15px\",\n                                          direction = \"auto\")) |&gt;\n  addLegend(pal = pal,\n            values = ~ nursing_summary$snf_mean_stay_round,\n            title = paste(\"Average SNF&lt;br&gt;Stay Length\"),\n            position = \"bottomright\")"
  },
  {
    "objectID": "projects/US_nursing_homes/index.html#plot-2-categorical",
    "href": "projects/US_nursing_homes/index.html#plot-2-categorical",
    "title": "United States Nursing Home Data",
    "section": "Plot 2 (categorical)",
    "text": "Plot 2 (categorical)\nNote: there are no observations in the $20 million - $25 million category so I did not provide a color for that level.\n\nnursing_summary &lt;- nursing_summary |&gt;\nmutate(cat_labs_1 = paste0(\"Total Gross Revenue: \", tot_gross_revenue, \"&lt;br&gt;\",\n                         \"Number of Nursing Homes: \", homes_per_state, \"&lt;br&gt;\",\n                         \"Average Gross Revenue Per Home: \", tot_revenue_homes_round))\n        \nlabels &lt;- lapply(nursing_summary$cat_labs_1, HTML)\n\nlevels(nursing_summary$revenue_cat)\n\n[1] \"Less than $10 million\"     \"$10 million - $15 million\"\n[3] \"$15 million - $20 million\" \"Greater than $25 million\" \n\nfactpal &lt;- colorFactor(c(\"#8FDA04FF\",\n                         \"#009F3FFF\",\n                         \"#132157FF\",\n                         \"#FFF800FF\"),\n                       levels(nursing_summary$revenue_cat))\n\n\nleaflet(nursing_summary) |&gt;\n  setView(lng = -96.25,\n          lat = 40,\n          zoom = 3.5) |&gt;\n  addTiles() |&gt; \n  addPolygons(weight = 2,\n              opacity = 1,\n              color = \"black\",\n              fillColor = ~ factpal(nursing_summary$revenue_cat),\n              dashArray = \"1\",\n              fillOpacity = 0.7,\n  highlightOptions = highlightOptions(weight = 5,\n                                      color = \"#666\",\n                                      fillOpacity = 0.7,\n                                      bringToFront = TRUE),\n  label = labels,\n  labelOptions = labelOptions(style = list(\"font-weight\" = \"normal\",\n                                           padding = \"3px 8px\"),\n                              textsize = \"15px\",\n                              direction = \"auto\")) |&gt;\n  addLegend(pal = factpal,\n            values = ~ nursing_summary$revenue_cat, \n            opacity = 0.7,\n            title = \"Gross Revenue\",\n            position = \"bottomright\")\n\n\n\n\n\nTWIN FOUNTAINS HOME of GA had a gross revenue of $1,300,406,865 and was removed for this analysis."
  },
  {
    "objectID": "projects/US_nursing_homes/index.html",
    "href": "projects/US_nursing_homes/index.html",
    "title": "United States Nursing Home Data",
    "section": "",
    "text": "In this project, I used the Skilled Nursing Facility Cost Report collected by the Centers for Medicare & Medicaid Services in order to investigate characteristics of nursing homes in the United States. The dataset includes a wide range of information about nursing homes, including revenue, number of beds, and average stay duration."
  },
  {
    "objectID": "projects/Gutenberg Data/index.html",
    "href": "projects/Gutenberg Data/index.html",
    "title": "Gutenberg Data",
    "section": "",
    "text": "#Scrape the top 100 books from the past 30 days\nget_gutenberg_top100 &lt;- function() {\n  if (robotstxt::paths_allowed(\"https://www.gutenberg.org/browse/scores/top#books-last30\") == \"TRUE\") {\n    gutenberg_page &lt;- read_html(\"https://www.gutenberg.org/browse/scores/top#books-last30\")\n    books_last30 &lt;- html_nodes(gutenberg_page, \"#books-last30+ ol li\")\n    books_last30_text &lt;- html_text(books_last30)\n    books_last30_tbl &lt;- tibble(\n  title = gsub(\" by.*\", \"\", books_last30_text),\n  author = gsub(\".* by \", \"\", books_last30_text),\n  popularity = seq.int(1,100)\n)\n    \n  df_books30 &lt;&lt;- books_last30_tbl\n  }\n}\n\nget_gutenberg_top100()\n\n\ntop_100_books &lt;- gutenberg_works() |&gt;\n  filter(title %in% df_books30$title)\n\nbook_ids &lt;- top_100_books$gutenberg_id\nbooks_with_warnings &lt;- list()\nbooks_with_warningsb &lt;- list()\ntop_100_data &lt;- data.frame()\n\ndownload_book &lt;- function(book_id, mirror = \"http://aleph.gutenberg.org\") {\n  tryCatch(\n    {\n      data &lt;- gutenberg_download(book_id, meta_fields = c(\"title\", \"author\"), mirror = mirror)\n      top_100_data &lt;&lt;- bind_rows(top_100_data, data)\n    },\n    warning = function(w) {\n      books_with_warnings &lt;&lt;- c(books_with_warnings, book_id)\n      message(\"Warning for book ID: \", book_id) \n      return(NULL)\n    }\n  )\n}\n\nbook_data &lt;- lapply(book_ids, download_book)\n\nprint(\"Books with warnings:\")\n\n[1] \"Books with warnings:\"\n\nprint(books_with_warnings)\n\n[[1]]\n[1] 11\n\n[[2]]\n[1] 46\n\n[[3]]\n[1] 100\n\n[[4]]\n[1] 120\n\n[[5]]\n[1] 145\n\n[[6]]\n[1] 174\n\n[[7]]\n[1] 345\n\n[[8]]\n[1] 730\n\n[[9]]\n[1] 1342\n\n[[10]]\n[1] 1513\n\n[[11]]\n[1] 2148\n\n[[12]]\n[1] 2199\n\n[[13]]\n[1] 2489\n\n[[14]]\n[1] 2641\n\n[[15]]\n[1] 19508\n\n[[16]]\n[1] 19640\n\n[[17]]\n[1] 41445\n\n[[18]]\n[1] 43936\n\n[[19]]\n[1] 51713\n\n[[20]]\n[1] 64317\n\n[[21]]\n[1] 67098\n\n[[22]]\n[1] 67979\n\ntop_100_data &lt;- top_100_data |&gt;\n  mutate(text = na_if(text, \"\")) |&gt; #changing empty lines to NA\n  na.omit() |&gt; #removing those empty (NA) lines\n  group_by(title) |&gt;\n  mutate(line_num = row_number()) |&gt; #adding line number (starts at 1 for each book)\n  ungroup()\n\n\n#print(top_100_data)\n#Note: this dataset is way too long to render to pdf. \n\n#For viewing\ntop_100_line_1 &lt;- top_100_data |&gt;\n  filter(line_num == 1)\nhead(top_100_line_1)\n\n# A tibble: 6 × 5\n  gutenberg_id text                                        title author line_num\n         &lt;int&gt; &lt;chr&gt;                                       &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;\n1           33 The Scarlet Letter                          The … Hawth…        1\n2           41 The Legend of Sleepy Hollow                 The … Irvin…        1\n3           42 [Illustration]                              The … Steve…        1\n4           45 ANNE OF GREEN GABLES                        Anne… Montg…        1\n5          150 ******************************************… The … Plato         1\n6          244 A STUDY IN SCARLET                          A St… Doyle…        1"
  },
  {
    "objectID": "projects/US_nursing_homes/index.html#join-data",
    "href": "projects/US_nursing_homes/index.html#join-data",
    "title": "United States Nursing Home Data",
    "section": "Join Data",
    "text": "Join Data\n\nMode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nstates_geo &lt;- states_sf |&gt; #creates data set with state names, abbreviations and geometry\n  right_join(state_abbr_data,\n             by = c(\"name\" = \"state\"))\n\nstates_geo &lt;- states_geo |&gt; #adds latitude, longitude, group, order\n  right_join(states_polygon,\n             by = c(\"name\" = \"region\"))\n\nnursing_summary &lt;- nursing_data |&gt;\n  filter(state_code != \"PR\" &\n         state_code != \"DC\") |&gt; #removes DC & Puerto Rico\n  filter(number_of_beds &lt; 1000 & gross_revenue &lt; 1000000000) |&gt;\n  mutate(type_of_control = as.factor(type_of_control), # creates factor with levels Voluntary, Proprietary, or Governmental from numerical variable type_of_control.\n         type_of_control = fct_recode(type_of_control,\n                           \"Voluntary Nonprofit-Church\" = \"1\",\n                           \"Voluntary Nonprofit-Other\" = \"2\",\n                           \"Proprietary-Individual\" = \"3\",\n                           \"Proprietary-Corporation\" = \"4\",\n                           \"Proprietary-Partnership\" = \"5\",\n                           \"Proprietary-Other\" = \"6\",\n                           \"Governmental-Federal\" = \"7\",\n                           \"Governmental-City-County\" = \"8\",\n                           \"Governmental-County\" = \"9\",\n                           \"Governmental-State\" = \"10\",\n                           \"Governmental-facility District\" = \"11\",\n                           \"Governmental-City\" = \"12\",\n                           \"Governmental-Other\" = \"13\"),\n         type_of_control = fct_collapse(type_of_control, Nonprofit = c(\"Voluntary Nonprofit-Church\",\n                                                                       \"Voluntary Nonprofit-Other\"),\n                                                         Proprietary = c(\"Proprietary-Individual\",\n                                                                         \"Proprietary-Corporation\",\n                                                                         \"Proprietary-Partnership\",\n                                                                         \"Proprietary-Other\"),\n                                                         Governmental = c(\"Governmental-Federal\",\n                                                                          \"Governmental-City-County\",\n                                                                          \"Governmental-County\",\n                                                                          \"Governmental-State\",\n                                                                          \"Governmental-facility District\",\n                                                                          \"Governmental-City\",\n                                                                          \"Governmental-Other\"))) |&gt;\n  group_by(state_code) |&gt;\n  summarize(homes_per_state = n(), #number of nursing homes per state\n            total_beds = sum(number_of_beds,\n                             na.rm = TRUE),  #total beds per state\n            snf_mean_stay = mean(snf_average_length_of_stay_total,\n                                 na.rm = TRUE), #mean snf stay length per state \n            top_control_type = Mode(type_of_control), #most common type of control per state\n            tot_gross_revenue = sum(gross_revenue, na.rm = TRUE), #sum gross revenue per state\n            tot_revenue_homes = tot_gross_revenue/homes_per_state) #total gross revenue/number of beds per state\n\n\n#creates a categorical variable from total gross revenue/number of beds per state\nnursing_summary &lt;- within(nursing_summary, {revenue_cat &lt;- NA \n                                            revenue_cat[tot_revenue_homes &lt; 10000000] &lt;- \"Less than $10 million\"\n                                            revenue_cat[tot_revenue_homes &gt;= 10000000 & tot_revenue_homes &lt; 15000000] &lt;- \"$10 million - $15 million\"\n                                            revenue_cat[tot_revenue_homes &gt;= 15000000 & tot_revenue_homes &lt; 20000000] &lt;- \"$15 million - $20 million\"\n                                            revenue_cat[tot_revenue_homes &gt;= 20000000 & tot_revenue_homes &lt; 25000000] &lt;- \"$20 million - $25 million\"\n                                            revenue_cat[tot_revenue_homes &gt;= 25000000] &lt;- \"Greater than $25 million\"}) |&gt;\n  mutate(revenue_cat = as.factor(revenue_cat),\n         revenue_cat = fct_relevel(revenue_cat, c(\"Less than $10 million\",\n                                                  \"$10 million - $15 million\",\n                                                  \"$15 million - $20 million\",\n                                                  \"$20 million - $25 million\",\n                                                  \"Greater than $25 million\")))\n\n\n nursing_summary &lt;- states_geo |&gt;\n  right_join(nursing_summary,\n             by = c(\"postal\" = \"state_code\")) |&gt; #adds geography data to summary data\n  left_join(pop_data,\n            by = c(\"name\" = \"state\")) |&gt; #adds additional population data\n  mutate(beds_pop = total_beds / population, #beds per person\n         beds_10k = beds_pop * 10000, #beds per 10,000 people\n         name = str_to_title(name),\n         snf_mean_stay_round = round(snf_mean_stay, digits = 2),\n         tot_revenue_homes_round = round(tot_revenue_homes, digits = 2)) |&gt;\n  filter(name != \"Hawaii\" & name != \"Alaska\") |&gt;\n  select(name,\n         postal,\n         total_beds,\n         population,\n         homes_per_state,\n         beds_pop,\n         beds_10k,\n         snf_mean_stay,\n         snf_mean_stay_round,\n         top_control_type,\n         tot_gross_revenue,\n         tot_revenue_homes,\n         tot_revenue_homes_round,\n         revenue_cat,\n         geometry,\n         lat, \n         long,\n         group,\n         order)\n   \n \n#getting statistics in order to create levels for new categorical variable (above).\ndistinct &lt;- nursing_summary |&gt;\n  st_drop_geometry() |&gt;\n  distinct(tot_revenue_homes)\n\nfavstats(~tot_revenue_homes,  data = distinct)\n\n     min      Q1   median       Q3      max     mean      sd  n missing\n 5114358 8139979 10157439 13258071 28429799 11113745 4200457 48       0"
  },
  {
    "objectID": "projects/US_nursing_homes/index.html#outlier-analysis",
    "href": "projects/US_nursing_homes/index.html#outlier-analysis",
    "title": "United States Nursing Home Data",
    "section": "Outlier Analysis",
    "text": "Outlier Analysis\n\noutliers_check &lt;- nursing_data |&gt;\n  select(facility_name, state_code, gross_revenue, number_of_beds, snf_average_length_of_stay_total)\n\nnursing_data |&gt;\n  ggplot(aes(gross_revenue, number_of_beds)) +\n  geom_point() +\n  theme_bw() +\n  labs(x = \"Gross Revenue\",\n       y = \"Number of Beds\")\n\n\n\n\n\n\n\nnursing_data |&gt;\n  filter(number_of_beds &lt; 1000 & gross_revenue &lt; 1000000000) |&gt;\n  ggplot(aes(gross_revenue, number_of_beds)) +\n  geom_point() +\n  theme_bw() +\n  labs(x = \"Gross Revenue\",\n       y = \"Number of Beds\")\n\n\n\n\n\n\n\n\nBased on this analysis, two points were removed from the dataset.\n- Twin Fountains Home (Georgia) had a gross revenue of $1,300,406,865\n- Sanilac County Medical Care Facility (Michigan) had 22,287 beds."
  },
  {
    "objectID": "projects/US_nursing_homes/index.html#joining-data",
    "href": "projects/US_nursing_homes/index.html#joining-data",
    "title": "United States Nursing Home Data",
    "section": "Joining Data",
    "text": "Joining Data\n\nMode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nstates_geo &lt;- states_sf |&gt; #creates data set with state names, abbreviations and geometry\n  right_join(state_abbr_data,\n             by = c(\"name\" = \"state\"))\n\nstates_geo &lt;- states_geo |&gt; #adds latitude, longitude, group, order\n  right_join(states_polygon,\n             by = c(\"name\" = \"region\"))\n\nnursing_summary &lt;- nursing_data |&gt;\n  filter(state_code != \"PR\" &\n         state_code != \"DC\") |&gt; #removes DC & Puerto Rico\n  filter(number_of_beds &lt; 1000 & gross_revenue &lt; 1000000000) |&gt;\n  mutate(type_of_control = as.factor(type_of_control), # creates factor with levels Voluntary, Proprietary, or Governmental from numerical variable type_of_control.\n         type_of_control = fct_recode(type_of_control,\n                           \"Voluntary Nonprofit-Church\" = \"1\",\n                           \"Voluntary Nonprofit-Other\" = \"2\",\n                           \"Proprietary-Individual\" = \"3\",\n                           \"Proprietary-Corporation\" = \"4\",\n                           \"Proprietary-Partnership\" = \"5\",\n                           \"Proprietary-Other\" = \"6\",\n                           \"Governmental-Federal\" = \"7\",\n                           \"Governmental-City-County\" = \"8\",\n                           \"Governmental-County\" = \"9\",\n                           \"Governmental-State\" = \"10\",\n                           \"Governmental-facility District\" = \"11\",\n                           \"Governmental-City\" = \"12\",\n                           \"Governmental-Other\" = \"13\"),\n         type_of_control = fct_collapse(type_of_control, Nonprofit = c(\"Voluntary Nonprofit-Church\",\n                                                                       \"Voluntary Nonprofit-Other\"),\n                                                         Proprietary = c(\"Proprietary-Individual\",\n                                                                         \"Proprietary-Corporation\",\n                                                                         \"Proprietary-Partnership\",\n                                                                         \"Proprietary-Other\"),\n                                                         Governmental = c(\"Governmental-Federal\",\n                                                                          \"Governmental-City-County\",\n                                                                          \"Governmental-County\",\n                                                                          \"Governmental-State\",\n                                                                          \"Governmental-facility District\",\n                                                                          \"Governmental-City\",\n                                                                          \"Governmental-Other\"))) |&gt;\n  group_by(state_code) |&gt;\n  summarize(homes_per_state = n(), #number of nursing homes per state\n            total_beds = sum(number_of_beds,\n                             na.rm = TRUE),  #total beds per state\n            snf_mean_stay = mean(snf_average_length_of_stay_total,\n                                 na.rm = TRUE), #mean snf stay length per state \n            top_control_type = Mode(type_of_control), #most common type of control per state\n            tot_gross_revenue = sum(gross_revenue, na.rm = TRUE), #sum gross revenue per state\n            tot_revenue_homes = tot_gross_revenue/homes_per_state) #total gross revenue/number of beds per state\n\n\n#creates a categorical variable from total gross revenue/number of beds per state\nnursing_summary &lt;- within(nursing_summary, {revenue_cat &lt;- NA \n                                            revenue_cat[tot_revenue_homes &lt; 10000000] &lt;- \"Less than $10 million\"\n                                            revenue_cat[tot_revenue_homes &gt;= 10000000 & tot_revenue_homes &lt; 15000000] &lt;- \"$10 million - $15 million\"\n                                            revenue_cat[tot_revenue_homes &gt;= 15000000 & tot_revenue_homes &lt; 20000000] &lt;- \"$15 million - $20 million\"\n                                            revenue_cat[tot_revenue_homes &gt;= 20000000 & tot_revenue_homes &lt; 25000000] &lt;- \"$20 million - $25 million\"\n                                            revenue_cat[tot_revenue_homes &gt;= 25000000] &lt;- \"Greater than $25 million\"}) |&gt;\n  mutate(revenue_cat = as.factor(revenue_cat),\n         revenue_cat = fct_relevel(revenue_cat, c(\"Less than $10 million\",\n                                                  \"$10 million - $15 million\",\n                                                  \"$15 million - $20 million\",\n                                                  \"$20 million - $25 million\",\n                                                  \"Greater than $25 million\")))\n\n\n nursing_summary &lt;- states_geo |&gt;\n  right_join(nursing_summary,\n             by = c(\"postal\" = \"state_code\")) |&gt; #adds geography data to summary data\n  left_join(pop_data,\n            by = c(\"name\" = \"state\")) |&gt; #adds additional population data\n  mutate(beds_pop = total_beds / population, #beds per person\n         beds_10k = beds_pop * 10000, #beds per 10,000 people\n         name = str_to_title(name),\n         snf_mean_stay_round = round(snf_mean_stay, digits = 2),\n         tot_revenue_homes_round = round(tot_revenue_homes, digits = 2)) |&gt;\n  filter(name != \"Hawaii\" & name != \"Alaska\") |&gt;\n  select(name,\n         postal,\n         total_beds,\n         population,\n         homes_per_state,\n         beds_pop,\n         beds_10k,\n         snf_mean_stay,\n         snf_mean_stay_round,\n         top_control_type,\n         tot_gross_revenue,\n         tot_revenue_homes,\n         tot_revenue_homes_round,\n         revenue_cat,\n         geometry,\n         lat, \n         long,\n         group,\n         order)\n   \n \n#getting statistics in order to create levels for new categorical variable (above).\ndistinct &lt;- nursing_summary |&gt;\n  st_drop_geometry() |&gt;\n  distinct(tot_revenue_homes)\n\nfavstats(~tot_revenue_homes,  data = distinct)\n\n     min      Q1   median       Q3      max     mean      sd  n missing\n 5114358 8139979 10157439 13258071 28429799 11113745 4200457 48       0"
  },
  {
    "objectID": "projects/US_nursing_homes/index.html#importing-data",
    "href": "projects/US_nursing_homes/index.html#importing-data",
    "title": "United States Nursing Home Data",
    "section": "Importing Data",
    "text": "Importing Data\n\n# Loading Nursing Home Data \n# https://data.cms.gov/provider-compliance/cost-report/skilled-nursing-facility-cost-report\nnursing_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/nursing_data.csv\") |&gt;\n  clean_names() |&gt;\n  select(-nursing_and_allied_health_education_activities)\n\n# Loading state abbreviations for for joining with geographic data\nstate_abbr_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/state_abbr.csv\") |&gt;\n  clean_names() |&gt;\n  select(-standard) |&gt;\n  mutate(state = str_to_lower(state))\n\n# Loading US states geographic data using sf and maps packages\nstates_sf &lt;- read_sf(\"https://rstudio.github.io/leaflet/json/us-states.geojson\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = str_to_lower(name))\n\nstates_polygon &lt;- map_data(\"state\") |&gt;\n  select(region, group, order, lat, long)\n\n# Loading state population data \n# https://www.pewtrusts.org/en/research-and-analysis/articles/2022/04/25/a-third-of-states-lost-population-in-2021\npop_data &lt;- read_csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/2020_pop.csv\") |&gt;\n  clean_names() |&gt;\n  mutate(state = str_to_lower(state))"
  },
  {
    "objectID": "projects/Ecological Data/index.html",
    "href": "projects/Ecological Data/index.html",
    "title": "EREN Research Project Analysis",
    "section": "",
    "text": "This analysis comapres EREN plot data collected by BIO 261’s lab groups in 2024 to historical data from 2015, focusing on the growth and health of tree species within various ecological plots. The dataset includes measurements from 2015 and 2024, allowing us to examine changes over nearly a decade. The analysis includes data cleaning, data transformations, statistical tests, and visualizations to explore relationships between tree characteristics and plot conditions.\n\nData Preparation and Cleaning\nWe start by importing and cleaning the datasets from 2015 and 2024 by removing spaces, handling null values, and standardizing data formats.\n\n\nCleaning 2015 Data\n\ndat_2015 &lt;- read.csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/Combined_2015_data.csv\") |&gt;\n  clean_names() |&gt;\n  mutate(across(everything(),\n                str_remove_all,\n                pattern = fixed(\" \"))) |&gt; #remove spaces in data\n  mutate(across(where(is.character),\n                ~na_if(., \"null\"))) |&gt; #add null vals for chrs\n  mutate(across(c(tree_number,\n                  subplot),\n                as.character)) |&gt; #convert to chr datatype\n  mutate(across(c(plot_year,\n                  plot_month,\n                  height,\n                  dbh),\n                as.numeric)) |&gt; #convert to numeric datatype\n  rename(dbh_2015 = dbh,\n          note_2015 = note,\n          plot_month_2015 = plot_month) \n\n\n\nCleaning 2024 Data\n\ndat_2024 &lt;- read.csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/Combined_2024_data.csv\") |&gt;\n  clean_names () |&gt;\n  select(-group) |&gt;\n  mutate(across(everything(),\n                str_remove_all,\n                pattern = fixed(\" \"))) |&gt; #remove spaces in data\n  mutate(across(where(is.character),\n                ~if_else(. %in% c(\"\",\n                                  \"unidentified\",\n                                  \"Dead/Missing\",\n                                  \"null\",\n                                  \"na\",\n                                  \"NA\",\n                                  \"Na\"),\n                          NA_character_, .))) |&gt; #add null vals for chrs\n  mutate(plot_month = str_replace(plot_month, \"September\", \"9\"),\n         plot_name = str_replace_all(plot_name, c(\"_\" = \"\",\n                                                  \"Plot4\" = \"southsouth\",\n                                                  \"4\" = \"southsouth\", \n                                                  \"northeast\" = \"northnorth\",\n                                                  \"notheast\" = \"northnorth\")),\n         plot_name = str_to_lower(plot_name)) |&gt; #standardizes plot_name & plot_month cols\n   mutate(across(c(height,\n                   dbh),\n                 na_if, \"0\")) |&gt; #add null vals for nums\n   mutate(dbh = na_if(dbh, \"61.5\")) |&gt; #REMOVING OUTLIER DBH\n   mutate(across(c(height,\n                   dbh,\n                   plot_year,\n                   plot_month),\n                 as.numeric)) |&gt; #convert to numeric datatype\n   mutate(across(c(height,\n                   dbh),\n                 round, 2)) |&gt; #round values to 2 decimal places\n   rename(dbh_2024 = dbh,\n          note_2024 = note,\n          height_2024 = height,\n          plot_month_2024 = plot_month) \n\n\n\nPreparation and Joining\nThe cleaned datasets are further processed to combine duplicated measurements for each tree, calculate growth rates, and identify dead trees. This allows for easy comparison of changes between 2015 and 2024.\n\n#averaging trees that were measured more than once in each data set\ndat_2015_new &lt;- dat_2015 |&gt;\n    group_by(plot_name,\n             tree_number) |&gt;\n    mutate(plot_month_2015 = Mode(plot_month_2015),\n           dbh_2015 = mean(dbh_2015,\n                           na.rm = TRUE)) |&gt; #taking the mean dbh of all trees with the same plot name and tree number\n  distinct(tree_number,\n           .keep_all = TRUE) |&gt;\n  select(-plot_year,\n         -plot_month_2015)\n\n\ndat_2024_new &lt;- dat_2024 |&gt;\n  group_by(plot_name,\n           tree_number) |&gt;\n  mutate(plot_month_2024 = Mode(plot_month_2024),\n         dbh_2024 = mean(dbh_2024,\n                         na.rm = TRUE),\n         height_2024 = mean(height_2024,\n                            na.rm = TRUE)) |&gt; #taking the mean dbh and height of all trees with the same plot name and tree number\n  distinct(tree_number,\n           .keep_all = TRUE) |&gt;\n  mutate(across(where(is.numeric),\n                ~na_if(., NaN))) |&gt; #changing not a number to NA\n  select(-plot_year,\n         -plot_month_2024)\n\n\n\nJoining & Creating New Variables\n\ndat_all &lt;- dat_2024_new |&gt;\n    left_join(dat_2015_new,\n              by = c(\"plot_name\",\n                     \"subplot\",\n                     \"tree_number\")) |&gt; \n    select(plot_name,\n           subplot,\n           tree_number,\n           species_code.y,\n           dbh_2015,\n           dbh_2024,\n           height_2024,\n           note_2015,\n           note_2024,\n           inv_status,\n           stemtype,\n           soundness,\n           crownclass,\n           treedamage) |&gt;\n  rename(species_code = species_code.y) |&gt;\n  mutate(treedamage = str_to_upper(treedamage),\n         growth_factor = (dbh_2024 - dbh_2015) / 9, #create growth factor col, 2024-2015/9yrs\n         dead_2015 = note_2015, #copy col\n         dead_2024 = note_2024) |&gt; #copy col\n  mutate(dead_2015 = case_when(str_detect(dead_2015, \"lvsgone\") ~ \"DEADNOLEAVES\",\n                               str_detect(dead_2015, \"noleavesleft\")  ~ \"DEADNOLEAVES\",\n                               str_detect(dead_2015, \"leavesgone\")  ~ \"DEADNOLEAVES\",\n                               str_detect(dead_2015, \"fewleaves\")  ~ \"DEADNOLEAVES\",\n                               str_detect(dead_2015, \"leavesallgone\")  ~ \"DEADNOLEAVES\",\n                               str_detect(dead_2015, \"mostleavesgone\")  ~ \"DEADNOLEAVES\",\n                               str_detect(dead_2015, \"dead\") ~ \"DEAD\",\n                               TRUE ~ dead_2015)) |&gt; #if contains left, convert to right\n  mutate(dead_2015 = replace(dead_2015,\n                             !grepl(\"DEAD\", dead_2015),\n                             \"NODATA\")) |&gt;\n  mutate(dead_2024 = case_when(str_detect(dead_2024, \"noleaves\") ~ \"DEADNOLEAVES\",\n                               str_detect(dead_2024, \"dead\") ~ \"DEAD\",\n                               str_detect(dead_2024, \"missing\") ~ \"DEAD\",\n                               str_detect(dead_2024, \"Gone\") ~ \"DEAD\",\n                               str_detect(dead_2024, \"Dead\") ~ \"DEAD\",\n                               str_detect(dead_2024, \"deceased\") ~ \"DEAD\",\n                               TRUE ~ dead_2024)) |&gt; #if !contain DEAD, convert to NODATA\n   mutate(dead_2024 = replace(dead_2024,\n                              !grepl(\"DEAD\", dead_2024),\n                              \"NODATA\")) |&gt; #if !contain DEAD, convert to NODATA\n   mutate(species_name = as.factor(species_code),\n          species_genus = as.factor(species_code)) |&gt;\n   mutate(species_name = fct_recode(species_name,\n                                    \"Amur Maple\" = \"ACEGIN\",\n                                    \"Boxelder\" = \"ACENEG\",\n                                    \"Red Maple\" = \"ACERUB\",\n                                    \"Sugar Maple\" = \"ACESAC\",\n                                    \"Bitternut Hickory\" = \"CARCOR\",\n                                    \"American Ash\" = \"FRAAME\",\n                                    \"Black Walnut\" = \"JUGNIG\",\n                                    \"Eastern Hophornbeam\" = \"OSTVIR\",\n                                    \"Bigtooth Aspen\" = \"POPGRA\",\n                                    \"Black Cherry\" = \"PRUSER\",\n                                    \"Chokecherry\" = \"PRUVIR\",\n                                    \"White Oak\" = \"QUEALB\",\n                                    \"Bur Oak\" = \"QUEMAC\",\n                                    \"Red Oak\" = \"QUERUB\",\n                                    \"Common Buckthorn\" = \"RHACAT\",\n                                    \"American Basswood\" = \"TILAME\",\n                                    \"American Elm\" = \"ULMAME\")) |&gt; #create new col species_name\n   mutate(species_genus = fct_collapse(species_genus,\n                                       Acer = c(\"ACEGIN\", \"ACENEG\", \"ACERUB\", \"ACESAC\"),\n                                       Caryus = c(\"CARCOR\"),\n                                       Fraxinus = c(\"FRAAME\"),\n                                       Juglans = c(\"JUGNIG\"),\n                                       Ostrya = c(\"OSTVIR\"),\n                                       Populus = c(\"POPGRA\"),\n                                       Prunus = c(\"PRUSER\", \"PRUVIR\"),\n                                       Quercus = c(\"QUEALB\", \"QUEMAC\", \"QUERUB\"),\n                                       Rhamnus = c(\"RHACAT\"),\n                                       Tilia = c(\"TILAME\"),\n                                       Ulmus = c(\"ULMAME\"))) |&gt; #create new col species_genus\n    mutate(plot_name_num = case_when(str_detect(plot_name, \"northnorth\") ~ 2,\n                                  str_detect(plot_name, \"northsouth\") ~ 1,\n                                  str_detect(plot_name, \"southnorth\") ~ 3,\n                                  str_detect(plot_name, \"southsouth\") ~ 4,)) |&gt; #plot name chr to numeric\n    mutate(hl_density = case_when(str_detect(plot_name, \"northnorth\") ~ \"Low Density\",\n                                  str_detect(plot_name, \"northsouth\") ~ \"Low Density\",\n                                  str_detect(plot_name, \"southnorth\") ~ \"High Density\",\n                                  str_detect(plot_name, \"southsouth\") ~ \"High Density\")) |&gt; #new col plots high or low density\n    mutate(species_name = as.factor(species_name))\n\n\n\nPivoting for Visualization\n\ndat_all_pivot &lt;- dat_all |&gt;\n  pivot_longer(cols = starts_with(\"dbh_\"),\n               names_to = \"year\",\n               values_to = \"dbh\",\n               names_prefix = \"dbh_\")\n\n\n#How many of each species are in each plot?\ntbl1 &lt;- table(dat_all$species_name, dat_all$plot_name)\ntbl1\n\n                     \n                      northnorth northsouth southnorth southsouth\n  American Ash                 3         43         18         45\n  Bur Oak                     24          1          0          0\n  Bigtooth Aspen               1          0          0          0\n  White Oak                   18          1          0          0\n  Red Oak                      2          0          1          0\n  Sugar Maple                  8          5          0          2\n  American Basswood            4          0          0          0\n  American Elm                 5          3          0          0\n  Bitternut Hickory            1          0          0          0\n  Chokecherry                  1          1          0          0\n  Black Cherry                 1          1          0          0\n  Black Walnut                 0          3         13          7\n  Boxelder                     0          5          4          2\n  Eastern Hophornbeam          0          5          0          0\n  Common Buckthorn             0          1          0          0\n  Red Maple                    0          0         24          5\n  Amur Maple                   0          0          6          0\n\nprop1 &lt;- prop.table(tbl1, margin = 1)\nprop1\n\n                     \n                      northnorth northsouth southnorth southsouth\n  American Ash        0.02752294 0.39449541 0.16513761 0.41284404\n  Bur Oak             0.96000000 0.04000000 0.00000000 0.00000000\n  Bigtooth Aspen      1.00000000 0.00000000 0.00000000 0.00000000\n  White Oak           0.94736842 0.05263158 0.00000000 0.00000000\n  Red Oak             0.66666667 0.00000000 0.33333333 0.00000000\n  Sugar Maple         0.53333333 0.33333333 0.00000000 0.13333333\n  American Basswood   1.00000000 0.00000000 0.00000000 0.00000000\n  American Elm        0.62500000 0.37500000 0.00000000 0.00000000\n  Bitternut Hickory   1.00000000 0.00000000 0.00000000 0.00000000\n  Chokecherry         0.50000000 0.50000000 0.00000000 0.00000000\n  Black Cherry        0.50000000 0.50000000 0.00000000 0.00000000\n  Black Walnut        0.00000000 0.13043478 0.56521739 0.30434783\n  Boxelder            0.00000000 0.45454545 0.36363636 0.18181818\n  Eastern Hophornbeam 0.00000000 1.00000000 0.00000000 0.00000000\n  Common Buckthorn    0.00000000 1.00000000 0.00000000 0.00000000\n  Red Maple           0.00000000 0.00000000 0.82758621 0.17241379\n  Amur Maple          0.00000000 0.00000000 1.00000000 0.00000000\n\ndat_all |&gt;\n  tabyl(species_name, plot_name) |&gt;\n  adorn_totals(c(\"row\", \"col\")) |&gt;\n  adorn_percentages(denominator = \"col\") |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns() |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\nspecies_name\nnorthnorth\nnorthsouth\nsouthnorth\nsouthsouth\nTotal\n\n\n\n\nAmerican Ash\n4.1% (3)\n58.1% (43)\n24.7% (18)\n69.2% (45)\n38.1% (109)\n\n\nBur Oak\n32.4% (24)\n1.4% (1)\n0.0% (0)\n0.0% (0)\n8.7% (25)\n\n\nBigtooth Aspen\n1.4% (1)\n0.0% (0)\n0.0% (0)\n0.0% (0)\n0.3% (1)\n\n\nWhite Oak\n24.3% (18)\n1.4% (1)\n0.0% (0)\n0.0% (0)\n6.6% (19)\n\n\nRed Oak\n2.7% (2)\n0.0% (0)\n1.4% (1)\n0.0% (0)\n1.0% (3)\n\n\nSugar Maple\n10.8% (8)\n6.8% (5)\n0.0% (0)\n3.1% (2)\n5.2% (15)\n\n\nAmerican Basswood\n5.4% (4)\n0.0% (0)\n0.0% (0)\n0.0% (0)\n1.4% (4)\n\n\nAmerican Elm\n6.8% (5)\n4.1% (3)\n0.0% (0)\n0.0% (0)\n2.8% (8)\n\n\nBitternut Hickory\n1.4% (1)\n0.0% (0)\n0.0% (0)\n0.0% (0)\n0.3% (1)\n\n\nChokecherry\n1.4% (1)\n1.4% (1)\n0.0% (0)\n0.0% (0)\n0.7% (2)\n\n\nBlack Cherry\n1.4% (1)\n1.4% (1)\n0.0% (0)\n0.0% (0)\n0.7% (2)\n\n\nBlack Walnut\n0.0% (0)\n4.1% (3)\n17.8% (13)\n10.8% (7)\n8.0% (23)\n\n\nBoxelder\n0.0% (0)\n6.8% (5)\n5.5% (4)\n3.1% (2)\n3.8% (11)\n\n\nEastern Hophornbeam\n0.0% (0)\n6.8% (5)\n0.0% (0)\n0.0% (0)\n1.7% (5)\n\n\nCommon Buckthorn\n0.0% (0)\n1.4% (1)\n0.0% (0)\n0.0% (0)\n0.3% (1)\n\n\nRed Maple\n0.0% (0)\n0.0% (0)\n32.9% (24)\n7.7% (5)\n10.1% (29)\n\n\nAmur Maple\n0.0% (0)\n0.0% (0)\n8.2% (6)\n0.0% (0)\n2.1% (6)\n\n\nNA\n8.1% (6)\n6.8% (5)\n9.6% (7)\n6.2% (4)\n7.7% (22)\n\n\nTotal\n100.0% (74)\n100.0% (74)\n100.0% (73)\n100.0% (65)\n100.0% (286)\n\n\n\n\n#How many of each species are dead in 2024?\ndat_all |&gt;\n  tabyl(species_name, dead_2024) |&gt;\n  adorn_totals(c(\"row\", \"col\")) |&gt;\n  adorn_percentages(denominator = \"col\") |&gt;\n  adorn_pct_formatting() |&gt;\n  adorn_ns() |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\nspecies_name\nDEAD\nDEADNOLEAVES\nNODATA\nTotal\n\n\n\n\nAmerican Ash\n12.0% (3)\n33.3% (2)\n40.8% (104)\n38.1% (109)\n\n\nBur Oak\n0.0% (0)\n0.0% (0)\n9.8% (25)\n8.7% (25)\n\n\nBigtooth Aspen\n0.0% (0)\n0.0% (0)\n0.4% (1)\n0.3% (1)\n\n\nWhite Oak\n0.0% (0)\n0.0% (0)\n7.5% (19)\n6.6% (19)\n\n\nRed Oak\n0.0% (0)\n0.0% (0)\n1.2% (3)\n1.0% (3)\n\n\nSugar Maple\n0.0% (0)\n0.0% (0)\n5.9% (15)\n5.2% (15)\n\n\nAmerican Basswood\n0.0% (0)\n0.0% (0)\n1.6% (4)\n1.4% (4)\n\n\nAmerican Elm\n0.0% (0)\n0.0% (0)\n3.1% (8)\n2.8% (8)\n\n\nBitternut Hickory\n0.0% (0)\n0.0% (0)\n0.4% (1)\n0.3% (1)\n\n\nChokecherry\n0.0% (0)\n0.0% (0)\n0.8% (2)\n0.7% (2)\n\n\nBlack Cherry\n0.0% (0)\n0.0% (0)\n0.8% (2)\n0.7% (2)\n\n\nBlack Walnut\n4.0% (1)\n50.0% (3)\n7.5% (19)\n8.0% (23)\n\n\nBoxelder\n32.0% (8)\n16.7% (1)\n0.8% (2)\n3.8% (11)\n\n\nEastern Hophornbeam\n0.0% (0)\n0.0% (0)\n2.0% (5)\n1.7% (5)\n\n\nCommon Buckthorn\n4.0% (1)\n0.0% (0)\n0.0% (0)\n0.3% (1)\n\n\nRed Maple\n0.0% (0)\n0.0% (0)\n11.4% (29)\n10.1% (29)\n\n\nAmur Maple\n20.0% (5)\n0.0% (0)\n0.4% (1)\n2.1% (6)\n\n\nNA\n28.0% (7)\n0.0% (0)\n5.9% (15)\n7.7% (22)\n\n\nTotal\n100.0% (25)\n100.0% (6)\n100.0% (255)\n100.0% (286)\n\n\n\n\n\n\n\nAmerican Ash DBH by Plot in 2015 and 2024\n\ndat_all_pivot |&gt;\nfilter(species_code == \"FRAAME\") |&gt;\nggplot(aes(plot_name, dbh, fill = year)) +\n  geom_boxplot() +\n    stat_boxplot(geom = \"errorbar\") +\n    stat_summary(fun.y = \"mean\", geom = \"point\", size = 2,\n                 position = position_dodge(width = 0.75), color = \"white\") +\n  theme_publish() +\n  scale_fill_manual(values = c(\"#38AAAB\", \"#DEF5E5\"))+\n  theme(aspect.ratio = 0.5,\n        panel.grid.major = element_line(colour = \"black\",\n                                        linewidth = 0.05)) +\n  labs(title = \"American Ash Tree DBH by Plot in 2015 and 2024\",\n       x = \"Plot Name\",\n       y = \"DBH (cm)\",\n       fill = \"Year\")\n\n\n\n\n\n\n\n#Statistical Analysis\n\n#T-Test\ndat_all_ash &lt;- dat_all |&gt;\n  filter(species_name == \"American Ash\")\n\nt.test(dbh_2024 ~ hl_density, data = dat_all_ash)\n\n\n    Welch Two Sample t-test\n\ndata:  dbh_2024 by hl_density\nt = 0.081381, df = 103.96, p-value = 0.9353\nalternative hypothesis: true difference in means between group High Density and group Low Density is not equal to 0\n95 percent confidence interval:\n -2.382149  2.586035\nsample estimates:\nmean in group High Density  mean in group Low Density \n                  13.38064                   13.27870 \n\nt.test(dbh_2015 ~ hl_density, data = dat_all_ash)\n\n\n    Welch Two Sample t-test\n\ndata:  dbh_2015 by hl_density\nt = -4.7587, df = 102.88, p-value = 6.384e-06\nalternative hypothesis: true difference in means between group High Density and group Low Density is not equal to 0\n95 percent confidence interval:\n -5.503890 -2.265709\nsample estimates:\nmean in group High Density  mean in group Low Density \n                  8.320635                  12.205435 \n\n#DBH vs plot location ANOVA\nmodel_2015_ash &lt;- aov(dbh_2015 ~ plot_name, data = dat_all_ash)\nsummary(model_2015_ash)\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nplot_name     3  479.7  159.91   8.888 2.66e-05 ***\nResiduals   105 1889.2   17.99                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodel_2015_ash$coefficients\n\n        (Intercept) plot_namenorthsouth plot_namesouthnorth plot_namesouthsouth \n          11.433333            0.825969           -1.369444           -3.810000 \n\ntukey15 &lt;- TukeyHSD(model_2015_ash)\nprint(tukey15)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = dbh_2015 ~ plot_name, data = dat_all_ash)\n\n$plot_name\n                           diff        lwr       upr     p adj\nnorthsouth-northnorth  0.825969  -5.786793  7.438731 0.9879593\nsouthnorth-northnorth -1.369444  -8.275206  5.536317 0.9546804\nsouthsouth-northnorth -3.810000 -10.413171  2.793171 0.4373882\nsouthnorth-northsouth -2.195413  -5.304217  0.913390 0.2589815\nsouthsouth-northsouth -4.635969  -6.997533 -2.274405 0.0000081\nsouthsouth-southnorth -2.440556  -5.528906  0.647795 0.1721049\n\nplot(tukey15, las = 0 , col = \"brown\", cex.axis=0.40)\n\n\n\n\n\n\n\nmodel_2024_ash &lt;- aov(dbh_2024 ~ plot_name, data = dat_all_ash)\nsummary(model_2024_ash)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)\nplot_name     3     37   12.36    0.28  0.839\nResiduals   102   4496   44.08               \n3 observations deleted due to missingness\n\nmodel_2024_ash$coefficients\n\n        (Intercept) plot_namenorthsouth plot_namesouthnorth plot_namesouthsouth \n          15.533333           -2.411938           -1.223039           -2.520233 \n\ntukey24 &lt;- TukeyHSD(model_2024_ash)\nprint(tukey24)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = dbh_2024 ~ plot_name, data = dat_all_ash)\n\n$plot_name\n                            diff        lwr      upr     p adj\nnorthsouth-northnorth -2.4119380 -12.767477 7.943601 0.9292169\nsouthnorth-northnorth -1.2230392 -12.082758 9.636679 0.9910924\nsouthsouth-northnorth -2.5202326 -12.875772 7.835307 0.9202635\nsouthnorth-northsouth  1.1888988  -3.779376 6.157173 0.9238205\nsouthsouth-northsouth -0.1082946  -3.848276 3.631687 0.9998438\nsouthsouth-southnorth -1.2971933  -6.265468 3.671081 0.9037437\n\nplot(tukey24, las = 0 , col = \"brown\", cex.axis=0.40)\n\n\n\n\n\n\n\n\n\n\nGrowth Factor by Plot\n\ndat_all |&gt;\n  ggplot(aes(hl_density, growth_factor, fill = hl_density)) +\n  geom_boxplot() +\n  stat_boxplot(geom = \"errorbar\", \n               width = 0.25) +\n  geom_boxplot() +\n  theme_publish() +\n  scale_fill_manual(values = c(\"#38AAAB\", \"#DEF5E5\"))+\n  theme(panel.grid.major = element_line(colour = \"black\",\n                                        linewidth = 0.05)) +\n  labs(title = \"Growth Factor by Ash Tree Density\",\n       x = \"Ash Tree Density\",\n       y = \"Growth Factor (cm/yr)\",\n       fill = \"Tree Density\")\n\n\n\n\n\n\n\ndat_all |&gt;\nggplot(aes(plot_name, growth_factor, fill = plot_name)) +\n  stat_boxplot(geom = \"errorbar\", \n               width = 0.25) +\n  geom_boxplot() +\n  theme_publish() +\n  scale_fill_viridis_d(option = \"mako\") +\n  theme(panel.grid.major = element_line(colour = \"black\",\n                                        linewidth = 0.05)) +\n  labs(title = \"Growth Factor by Plot\",\n       x = \"Plot Name\",\n       y = \"Growth Factor (cm/yr)\",\n       fill = \"Plot Name\")\n\n\n\n\n\n\n\n#Statistical Analysis\n#T-test\nt.test(growth_factor ~ hl_density, data = dat_all)\n\n\n    Welch Two Sample t-test\n\ndata:  growth_factor by hl_density\nt = 3.8956, df = 230.52, p-value = 0.0001284\nalternative hypothesis: true difference in means between group High Density and group Low Density is not equal to 0\n95 percent confidence interval:\n 0.1299268 0.3958522\nsample estimates:\nmean in group High Density  mean in group Low Density \n                 0.4635862                  0.2006966 \n\nggqqplot(dat_all, x = \"growth_factor\", facet.by = \"hl_density\")\n\n\n\n\n\n\n\n#dat_all &lt;- dat_all |&gt;\n#  mutate(log_growth = log(growth_factor + 2))\n\n#ggqqplot(dat_all, x = \"log_growth\", facet.by = \"hl_density\")\n#t.test(log_growth ~ hl_density, data = dat_all)\n#commented out log transform doesn't help\n\n#The true difference in mean growth factor between the high density and low density plots is not equal to zero. We are 95% confident that the true difference in mean growth factor between the high and low density plots is between 0.071 and 0.377 cm/yr. p-value = 0.004385.\n\n\n\nGrowth Factor by Genus\n\n#Rhamnus not shown because there was only 1 indivdiual in 2015 which died by 2024. \ndat_all |&gt;\nfilter(is.na(species_code) == FALSE & species_genus != \"Rhamnus\") |&gt;\nggplot(aes(reorder(species_genus, growth_factor, mean), growth_factor, fill = (reorder(species_genus, growth_factor, mean)))) +\n  stat_boxplot(geom = \"errorbar\", \n               width = 0.25) +\n  geom_boxplot() +\n  theme_publish() +\n  scale_fill_viridis_d(option = \"mako\") +\n  theme(panel.grid.major = element_line(colour = \"black\",\n                                        linewidth = 0.05)) +\n  labs(title = \"Growth Factor by Genus\",\n       x = \"Genus\",\n       y = \"Growth Factor (cm/yr)\",\n       fill = \"Genus\")\n\n\n\n\n\n\n\n\n\n\nSpecies and Growth Factor in High and Low Density Plots\n\n#High Density Only\ndat_all |&gt;\n  group_by(species_name) |&gt;\n  summarise(count = n()) |&gt;\n  filter(count &gt; 10)\n\n# A tibble: 8 × 2\n  species_name count\n  &lt;fct&gt;        &lt;int&gt;\n1 American Ash   109\n2 Bur Oak         25\n3 White Oak       19\n4 Sugar Maple     15\n5 Black Walnut    23\n6 Boxelder        11\n7 Red Maple       29\n8 &lt;NA&gt;            22\n\n#There are at least 10 trees of American Ash, Bur Oak, White Oak, Sugar Maple, Black Walnut, Boxelder, Red Maple. \n\n# There are more species (16) in the low density plot vs the high density plot (8)\ndat_all |&gt;\n  group_by(hl_density) |&gt;\n  summarize(unique_species_n = n_distinct(species_name))\n\n# A tibble: 2 × 2\n  hl_density   unique_species_n\n  &lt;chr&gt;                   &lt;int&gt;\n1 High Density                8\n2 Low Density                16\n\ndat_all |&gt;\nfilter(is.na(species_code) == FALSE & hl_density == \"High Density\") |&gt;\nfilter(species_name %in% c(\"American Ash\", \"Bur Oak\", \"White Oak\", \"Sugar Maple\", \"Black Walnut\", \"Boxelder\", \"Red Maple\")) |&gt;\nggplot(aes(reorder(species_name, growth_factor, mean), growth_factor, fill = (reorder(species_name, growth_factor, mean)))) +\n  stat_boxplot(geom = \"errorbar\", \n               width = 0.25) +\n  geom_boxplot() +\n  theme_publish() +\n  scale_fill_viridis_d(option = \"mako\") +\n  theme(panel.grid.major = element_line(colour = \"black\",\n                                        linewidth = 0.05)) +\n  labs(title = \"Growth Factor by Species in High Ash Density Plots\",\n       x = \"Species\",\n       y = \"Growth Factor (cm/yr)\",\n       fill = \"Species\")\n\n\n\n\n\n\n\n#Low Density Only\ndat_all |&gt;\nfilter(is.na(species_code) == FALSE & hl_density == \"Low Density\") |&gt;\nfilter(species_name %in% c(\"American Ash\", \"Bur Oak\", \"White Oak\", \"Sugar Maple\", \"Black Walnut\", \"Boxelder\", \"Red Maple\")) |&gt;\nggplot(aes(reorder(species_name, growth_factor, mean), growth_factor, fill = (reorder(species_name, growth_factor, mean)))) +\n  stat_boxplot(geom = \"errorbar\", \n               width = 0.25) +\n  geom_boxplot() +\n  theme_publish() +\n  scale_fill_viridis_d(option = \"mako\") +\n  theme(panel.grid.major = element_line(colour = \"black\",\n                                        linewidth = 0.05)) +\n  labs(title = \"Growth Factor by Species in Low Ash Density Plots\",\n       x = \"Species\",\n       y = \"Growth Factor (cm/yr)\",\n       fill = \"Species\")\n\n\n\n\n\n\n\n#There aren't any Bur Oak or White Oak in the High Density plots."
  },
  {
    "objectID": "projects/Historical Redlining/index.html",
    "href": "projects/Historical Redlining/index.html",
    "title": "Redlining in Minneapolis and St. Paul",
    "section": "",
    "text": "Historically, redlining has had a prominent impact on the city of Minneapolis. Housing in Minneapolis and its suburbs today are still segregated by neighborhood and municipality, impacting school districts, leading to segregated schools. We are interested in finding if redlining has an impact on the resources allocated to the public schools, specifically looking at resources including staffing, teacher salaries, educational attainment, and graduation rates.\nBeginning in the 1910s, tens of thousands of racial covenants first started being included in a property’s deed in Minneapolis. A racial covenant is the language included in a property’s deed prohibiting any person of color from buying or living in the property. [^(Sommer, 2020)] Due to this inequity among many other injustices, Minneapolis has some of the largest racial wealth gaps in the United States. Even today, those neighborhoods where racial covenants were included in the property deeds are still mostly white.\nThe impacts of redlining are seen today through health disparities, wealth gaps, housing insecurity, residential segregation and property values. Residential segregation impacts the enrollment to schools, and property taxes fund the schools [^“Redlining and Neighborhood Health”]. Neighborhoods with lower property taxes often have schools with less resources and funding, where neighborhoods with higher property taxes often have schools with more resources and funding. This project is looking at resources allocated to Minneapolis and St. Paul public schools, in Hennepin, Ramsey, and Dakota counties.\n\nData We Used\n\nlibrary(tidyverse)\nlibrary(mapview)\nlibrary(sf)\nlibrary(viridis)\nlibrary(RColorBrewer)\nsf_use_s2(FALSE)\n\n\n# Mapping Inequality Data\n# Link: https://dsl.richmond.edu/panorama/redlining/data \n\nmsp_holc = st_read(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/mappinginequality.json\") %&gt;% #Read in data\n  filter(state == \"MN\" & \n        (city == \"Minneapolis\" |\n        city == \"St. Paul\")) %&gt;% #Filter for Minneapolis and St. Paul\n  st_transform(4326) %&gt;%\n  st_as_sf()\n\nReading layer `mappinginequality' from data source \n  `https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/mappinginequality.json' \n  using driver `GeoJSON'\nSimple feature collection with 10154 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -122.7675 ymin: 25.70537 xmax: -69.60044 ymax: 48.2473\nGeodetic CRS:  WGS 84\n\n# Education Data\n# Link: https://educationdata.urban.org/documentation/#direct_access\n\nmsp_schools &lt;- read.csv(\"https://raw.githubusercontent.com/elisefeld/elise_data_dump/main/EducationDataPortal_05.01.2024_Schools.csv\") %&gt;%\n  select(-year, -ncessch, -state_location, -bureau_indian_education, -gleaid, -school_id, -leaid, -geocode_accuracy, -geocode_accuracy_detailed, -state_leaid, -state_fips_geo, -seasch, -county_fips_geo, -puma, -state_mailing, -census_region, -census_division, -csa, -cbsa, -phone, -fips, -cbsa_type, -cbsa_city, -city_mailing) %&gt;% #Remove unnecessary columns\n  filter((city_location == \"MINNEAPOLIS\"|\n         city_location == \"NORTH SAINT PAUL\"|\n         city_location == \"WEST SAINT PAUL\"|\n         city_location == \"SAINT PAUL\"|\n         city_location == \"SAINT PAUL PARK\"|\n         city_location == \"SOUTH SAINT PAUL\") & #Filter for Minneapolis and St. Paul \n         school_status == \"Open\") %&gt;% # Filter for open schools only\n         drop_na(c(geo_longitude, geo_latitude)) %&gt;%\n         st_as_sf(coords = c(\"geo_longitude\",\"geo_latitude\"), \n                           crs = st_crs(4326))\n\n\npip &lt;- st_join(msp_schools, msp_holc, join = st_within)\n\n#Turn Column \"School Level\" into factor and reorder\npip$school_level &lt;- as.factor(pip$school_level)\npip$school_level &lt;- fct_collapse(pip$school_level, \n             Elementary = c(\"Prekindergarten\", \"Primary\"),\n             Middle = c(\"Middle\"),\n             High = c(\"High\", \"Secondary\"),\n             Other = c(\"Other\"))\npip$school_level &lt;- fct_relevel(pip$school_level, \"High\", \"Middle\", \"Elementary\", \"Other\")\n\n\n\n\n#Summary Statistics for Salaries of Teachers Per Grade\nmosaic::favstats(salaries_teachers ~ grade, data = pip)\n\n  grade    min      Q1  median      Q3     max    mean        sd  n missing\n1     A 467297 1366965 1970146 2895196 6235242 2295896 1497834.8 12       5\n2     B  25675 1152387 1727862 2486169 8016135 2158596 1732105.3 49      30\n3     C  44013  676000 1365883 2274458 4944074 1620509 1145169.1 53      25\n4     D   7702  264977  826044 1649816 4250729 1016528  857425.7 37      31\n\n# Convert teacher salary from numeric into factor with $1,500,000 increments\npip &lt;- within(pip, {   \n  salaries_teachers_cat &lt;- NA \n  salaries_teachers_cat[salaries_teachers &lt; 1500000] &lt;- \"$0 - $1,500,000\"\n  salaries_teachers_cat[salaries_teachers &gt;= 1500000 & salaries_teachers &lt; 3000000] &lt;- \"$1,500,000 - $3,000,000\"\n  salaries_teachers_cat[salaries_teachers &gt;= 3000000 & salaries_teachers &lt; 4500000] &lt;- \"$3,000,000 - $4,500,000\"\n  salaries_teachers_cat[salaries_teachers &gt;= 4500000 & salaries_teachers &lt; 6000000] &lt;- \"$4,500,000 - $6,000,000\"\n  salaries_teachers_cat[salaries_teachers &gt;= 600000 & salaries_teachers &lt; 7500000] &lt;- \"$6,000,000 - $7,500,000\"\n  salaries_teachers_cat[salaries_teachers &gt;= 9000000] &lt;- \"$7,500,000 - $9,000,000\"\n   } )\n\n\n\nGraphs\nIn 1935, the Home Owners Loan Corporation created maps to determine the level of security for real estate investments, ranging from best, still desirable, definatly declining, and hazardous. The grades were based on housing quality, sale and rent history, and the racial and ethnic identity of the area.\nWe first obtained data regarding teachers’ grades, salaries, school names, enrollments, among many other variables from the Education Data Portal at the Urban Institute, where we filtered for just school districts in Hennepin, Ramsey, and Dakota counties. After importing this data into R, first we looked at the number of schools per grade in Minneapolis and St. Paul. Our graph tells us that we have data for a greater number of schools in “still desirable,” “defiantly declining,” and “hazardous” categories than we do for the “best” category.\n\n\nNumber of Schools Per Grade in Minneapolis and St. Paul\n\n#count number of schools per grade\nschools_per_grade &lt;- pip |&gt; \n  group_by(grade) |&gt; \n  summarise(school_name_count = n_distinct(school_name))\n\n#Barplot created \nggplot(schools_per_grade, aes(x = grade, y = school_name_count, fill = grade)) +\n  geom_bar(stat='identity') +\n  guides(fill=\"none\") +\n  labs(title = \"Number of Schools per Grade in Minneapolis and St. Paul\",\n       x = \"Grade\",\n       y = \"Number of Schools\") +\n  scale_fill_viridis_d(option = \"plasma\", na.value = \"grey50\") +\n  theme_bw()\n\n\n\n\n\n\n\n# y-axis is number of schools and x-axis is grade\n\nAlt-text for graph:\nThis is a bar graph and illustrates the number of schools in Minneapolis and St. Paul for each grade. Grade (A, B, C, D, or NA) is on the x-axis and number of schools is on the y-axis. The variable number of schools ranges from 0 to 100. The appearance of the graph tells us that there is a larger amount of schools in areas graded B, C, and D (around 75) than there are schools in grade A. In addition, there are more NAs or unknown data than there is data for any one grade, which is also interesting to note.\n\n\nTeacher Salaries By Grade in Hennepin, Ramsey, and Dakota Counties\nNext, we created a bar graph illustrating the average teacher salaries in schools for each grade (A, B, C, or D), in addition to a map displaying each grade with information about teacher salary and each school. Below you can see both the map and bar graph:\n\npip %&gt;%\n  filter(grade != \"NA\" & salaries_teachers_cat != \"NA\") %&gt;%\n    ggplot(aes(fill=salaries_teachers_cat, y=grade)) + \n      geom_bar() +\n      scale_fill_viridis(option = \"plasma\", discrete = TRUE) +\n      labs(title = \"Teacher Salaries By Grade in Hennepin, Ramsey, and Dakota Counties\",\n           x = \"Count\",\n           y = \"Investment Security Grade\",\n           fill = \"Teacher Salaries\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAlt-text for graph:\nThis is a stacked barplot, which shows a distribution of teacher salaries within each grade. It is titled “Teacher Salaries By Grade in Hennepin, Ramsey, and Dakota Counties,” with a key indicating six colors representing different ranges of teacher salaries for each bar. Teacher salaries range from $7,500,000 to $9,000,000, $6,000,000 to $7,500,000, $4,500,000 to $6,000,000, $3,000,000 to $4,500,000, $1,500,000 to $3,000,000, and $0 to $1,500,000. The x-axis represents the variable count and the y-axis displays the variable investment security grade, which is the level of security for real estate investments created by the Home Owners Loan Corporation. Investment security grade is listed in ascending order, starting with A (“most desirable”) and ending with D (“least desirable). The range of the variable count is from 0 to around 80 for the number of salaries per each grade. Overall, the appearance of the graph tells us that the grades B, C, and D have a very similar distribution of salaries which are in the 0 to $1,500,000 range. However, when you look closer at the data, grade D does have the lowest salary reported ($7702) and the lowest mean salary of all the other grades at $1,016,528. Another part that stands out is that there are only 12 salaries recorded for grade A when compared to about 49, 53, and 37 salaries recorded for the rest of the grades. In grade A, no salaries reached the $7,500,000 - $9,000,000 range, and the highest range is from $4,500,000 to $6,000,000.\n\npal &lt;- colorRampPalette(brewer.pal(9, \"YlOrRd\"))\n\npip %&gt;%\n    select(school_name, lea_name, school_level, school_type, enrollment, title_i_eligible, magnet, virtual, lunch_program, salaries_teachers_cat, grade) %&gt;%\n  mapview(zcol = \"salaries_teachers_cat\", col.regions = pal, layer.name = \"Teacher Salaries\") +\nmsp_holc %&gt;%\n  select(city, category, grade) %&gt;%\n  mapview(zcol = \"grade\", layer.name = \"Grade\")\n\n\n\n\n\nAlt-text for map:\nThis is an interactive map, which illustrates where each grade (A, B, C, and D) are located on a map of Minneapolis and St. Paul. It also displays teacher salaries for each school. Each grade is represented by a block or square-like shape that is either purple (A), blue (B), green (C), yellow (D), and gray (for NA). Each dot on the map represents a specific school, the color of the dot representing salary ranges from $7,500,000 to $9,000,000, $6,000,000 to $7,500,000, $4,500,000 to $6,000,000, $3,000,000 to $4,500,000, $1,500,000 to $3,000,000, $0 to $1,500,000, and NA values. When you click on an area of a specific grade, you can view the city, category, grade, and geometry information. When you interact with a specific dot on the map, you can view information about the school_name, district, school level, school type, amount of students enrolled, lunch programs, teacher salaries, and grade level. Ultimately, the appearance of the map tells us that there are fewer A grades overall in the map of Minneapolis and St. Paul. Neighborhoods like Southwest are classified as A, Longfellow is for the most part categorized as B, Phillips as C, and Sumner-Glenwood as D. Teacher salaries are also lowest on average for neighborhoods in grade D.\n\n\nInterpreting Map\nWhile this map contains a lot of useful and detailed information, it may also initially feel overwhelming. We started to find patterns within the data displayed on the map, including the fact that on average, neighborhoods categorized as grade A had higher teacher salaries when compared to other grade levels. We also calculated some summary statistics included at the end of our “Data We Used” section to help further interpret the teacher salary data for each grade. Our findings showed us that grade A’s mean salary was still the highest out of all the other grades, while the mean teacher’s salary for grade D was the lowest overall. Teachers’ mean salary for grade A was $2,295,896, grade B’s mean salary was $2,158,596, grade C’s mean salary $1,620,509, and the mean salary for grade D was $1,016,528.\n\n\nSchool Enrollment by Grade\n\npip |&gt;\n  filter(grade != \"NA\" & school_level != \"Other\") |&gt;\n  ggplot(aes(enrollment, fill = school_level)) +\n  geom_boxplot(alpha = 0.7) +\n  facet_wrap(~category) +\n  labs(title = \"School Enrollment by Grade\",\n       x = \"Enrollment\",\n       fill = \"School Level\") +\n  scale_fill_viridis(option = \"plasma\", discrete = TRUE) +\n  theme_bw() +\n  coord_flip()\n\n\n\n\n\n\n\n\nAlt-text for School Enrollment by Grade bar plot This is a bar plot describing school enrollment across security grades, with enrollment ranging from 0 to 1500. All school levels remain fairly stable across grades, with elementary school having around 250 students, middle school ranging from 200 to around 500, and high schools having an an average of around 150 across the categories. High school in “best” and “still desirable” have the most variation, ranging from around 100 to around 950.\n\n\nFull Time Social Workers by Grade\n\npip |&gt;\n  filter(grade != \"NA\" & school_level != \"Other\") |&gt;\n  ggplot(aes(social_workers_fte, fill = school_level)) +\n  geom_boxplot(alpha = 0.7) +\n  facet_wrap(~category) +\n  labs(title = \"Full Time Social Workers by Grade\",\n       x = \"Social Workers FTE\",\n       fill = \"School Level\") +\n  scale_fill_viridis(option = \"plasma\", discrete = TRUE) +\n  theme_bw() +\n  coord_flip()\n\n\n\n\n\n\n\n\nAlt-text for Full Time Social Workers by Grade boxplot: This is a box plot showing full time social workers by grade for each school level, with full time social working ranging from 0 to 5. For the elementary school level, the average number of social workers across the grades is one. The average number of social workers for middle schools begin to vary more, with the “best” category having an average of two full time social workers, around one and a half for “still desireable” and “defiantly declining”. For high schools, there is more variation for the amount of full time social workers, with the ranges of social workers being larger per grade. “Best” had the highest average of two and a half full time social workers, “still desirable” and defiantly declining” having an average of one full time social worker. High schools in the “hazardous” category having the lowest average number of full time social workers at zero.\n\n\nFull Time Support Staff by Grade\n\npip |&gt;\n  filter(grade != \"NA\" & school_level != \"Other\") |&gt;\n  ggplot(aes(support_fte, fill = school_level)) +\n  geom_boxplot(alpha = 0.7) +\n  facet_wrap(~category) +\n  labs(title = \"Full Time Support Staff by Grade\",\n       x = \"Support Staff FTE\",\n       fill = \"School Level\") +\n  scale_fill_viridis(option = \"plasma\", discrete = TRUE) +\n  theme_bw() +\n  coord_flip()\n\n\n\n\n\n\n\n\nAlt-text for Full Time Support Staff by Grade boxplot This is a box plot showing full time support staff by grade, with support staff ranging from 0 to 30. There are about the same number of full time support staff for elementary schools, about three or four full time support staff across the grades. Elementary schools also had the most outliers, with outliers in the “still desirable,” “defiantly declining,” and “hazardous” categories. Full time support staff for middle schools in all grades remain relatively consistent across grades. Support staff for high school shows some difference across grades, with around eight full time support staff in the “best” category, around four for “still desirable” and “defiantly declining” categories. The “hazardous” category has the lowest average number of full time support staff with an average of zero.\n\n\nFull Time Counselors by Grade\n\npip |&gt;\n  filter(grade != \"NA\" & school_level != \"Other\") |&gt;\n  ggplot(aes(counselors_fte, fill = fct_rev(school_level))) +\n  geom_boxplot(alpha = 0.7) +\n  facet_wrap(~category) +\n  labs(title = \"Full Time Counselors by Grade\",\n       x = \"Counselors FTE\",\n       fill = \"School Level\") +\n  scale_fill_viridis(option = \"plasma\", discrete = TRUE) +\n  theme_bw() +\n  coord_flip()\n\n\n\n\n\n\n\n\nAlt-text for Full Time Counselors by Grade boxplot This is a box plot showing the number of full time counselors by grade, with number of counselors rnaging from 0 to 6. Elementary schools are the most stable across the grades, with the lowest number of full time counselors compared to middle and high schools, with an average of one or zero full time counselors. Middle schools show a slight difference in number of full time counselors, with an average of two full time counselors in the “best” category. The number of full time counselors for middle and high school grades were similar, with an average of one for “still desirable” and “definitely declining.” There is an average of zero full time counselors in the “hazardous” grade for both middle and high schools. The highest average number of full time counselors is 2.5, in the “best” grade at the high school level.\n\n\nConclusion\nUltimately, the data we used does not show redlining to have much of an impact on resources allocated or salaries, but that doesn’t mean that there are no impacts of redlining in Minneapolis Public Schools. For example, school districts in Sumner-Glenwood, grade D, generally all had teacher salaries ranging from $0 to $3,000,000, which was lower when compared to other school districts in different grade areas. However, because the count we have is for total salaries of all teachers then we don’t know if it is because they have more teachers (and therefore the total amount they are paying is more). But most importantly we can’t make a conclusion about individual salaries. In addition, because the data is limited and due to several NA values, we can’t make any significant statistical claims that these grades have impacted teacher salaries when only looking at the data we analyzed.\nWhen examining data on school enrollment, full time social workers, full time support staff, and full time counselors by grade, we found some surprising results. We expected that schools in the “hazardous” areas would have less support staff or social workers, yet the numbers were very close for many of them, although the “hazardous” category did tend to have lower numbers.\nWe found that in high schools, the number of support staff in the “hazardous” category was on average less (0) than the number of counselors in “best,” “still desirable,” and “definitely declining”. “Best” had a higher average number of support staff (10), though because the number of total support staff was very small across all the grades, the difference is small. However, it does display how gaps begin to be noticeable in numbers of support staff or other resources across areas with different grades. This especially becomes noticeable when comparing data from elementary school to high school.\nWe can’t come to a conclusion based on the data we used as we didn’t complete our statistical analysis, along with having a limited data set.\nIn searching for data to use, we encountered several challenges, links to public data were either broken or unavailable to use, especially concerning data in recent years. The difficulty getting data from Minneapolis Public Schools is slightly concerning, considering the strike in 2022 and major budget cuts in 2024. The fact that there is not a lot of public access to data or several missing data entries might possibly indicate that schools are covering up data that they do not want to share, specifically regarding information about schools, graduation rates, salary rates, and how they differ geographically and by grade.\n\n\nSources\nhttps://educationdata.urban.org/data-explorer/explorer\nhttps://www.npr.org/2020/06/18/877460056/minneapolis-has-a-bold-plan-to-tackle-racial-inequity-now-it-has-to-follow-throu\nhttps://ncrc.org/holc-health/\nhttps://mnatlas.org/resources/graded-neighborhoods-by-home-owners-loan-corporation/\nhttps://public.education.mn.gov/MDEAnalytics/DataTopic.jsp?TOPICID=545\nhttps://www.nytimes.com/2021/11/27/us/minneapolis-school-integration.html\nhttps://www.axios.com/local/twin-cities/2024/05/16/school-segregation-integration-brown-v-board-anniversary\nhttps://www.axios.com/2024/05/14/school-segregation-brown-eudcation-ruling-70th\nhttps://tcf.org/content/report/school-integration-america-looks-like-today/\n[^(Sommer, 2020)]: This citation was from the article “Minneapolis Has A Bold Plan To Tackle Racial Inequity. Now It Has To Follow Through” written by Lauren Sommer (https://www.npr.org/2020/06/18/877460056/minneapolis-has-a-bold-plan-to-tackle-racial-inequity-now-it-has-to-follow-throu).\n[^“Redlining and Neighborhood Health”]: This citation was from the article “Redlining and Neighborhood Health” by Jason Richardson, Bruce C. Mitchell, Helen C.S. Meier, Emily Lynch, and Jad Edlebi (https://ncrc.org/holc-health/)."
  },
  {
    "objectID": "about.html#lipid-droplet-counting-in-tetrahymena-thermophila",
    "href": "about.html#lipid-droplet-counting-in-tetrahymena-thermophila",
    "title": "About Me",
    "section": "Lipid Droplet Counting in Tetrahymena Thermophila",
    "text": "Lipid Droplet Counting in Tetrahymena Thermophila\nThe Lipid Lab at St. Olaf investigates factors affecting the formation of lipid droplets in the model organism Tetrahymena thermophila. To gather data, students in lab have manually counted lipid droplets. Each organism can have up to several hundred droplets, and each image from the microscope can have several organisms. I created a program, lipidcountr, that uses image processing to automate the counting of lipid droplets in these cells.\nTalk: Quantification of Lipid Droplets in Tetrahymena thermophila at the 2023 Midwest Protozoology Conference in Galesburg, Illinois."
  },
  {
    "objectID": "about.html#impact-of-mental-health-stigma-on-outcomes-in-pheochromocytoma",
    "href": "about.html#impact-of-mental-health-stigma-on-outcomes-in-pheochromocytoma",
    "title": "About Me",
    "section": "Impact of Mental Health Stigma on Outcomes in Pheochromocytoma",
    "text": "Impact of Mental Health Stigma on Outcomes in Pheochromocytoma\nPheochromocytoma and Paraganglioma are rare neuroendocrine tumors that are often misdiagnosed. In this research project, I surveyed patients who were diagnosed with this condition on their experiences navigating the healthcare system. It was presented at the 2022 HOSA International Leadership Conference in Nashville, Tennessee.\nView Poster"
  },
  {
    "objectID": "about.html#autofilling-the-standard-form-180",
    "href": "about.html#autofilling-the-standard-form-180",
    "title": "About Me",
    "section": "Autofilling the Standard Form 180",
    "text": "Autofilling the Standard Form 180\nThe GSA standard form 180 (SF180) is a form necessary for requesting military records from the National Archives per 36 CFR 1233.18(d). When requesting the records of several military personnel, the completion of a large quantity of forms is time consuming and error prone. While requesting records for the missing sailors of the U.S.S Turner, I wrote a simple python script that enables researchers to automatically fill a large number of these forms using a spreadsheet template.\nFor more examples of my work in statistics and data science, see the project tab."
  }
]